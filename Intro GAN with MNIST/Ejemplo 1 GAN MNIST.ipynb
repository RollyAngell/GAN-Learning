{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "old_v = tf.logging.get_verbosity()\n",
    "tf.logging.set_verbosity(tf.logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x17799a08c50>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(mnist.train.images[12].reshape(28,28), cmap='Greys')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator(z,reuse=None):\n",
    "    with tf.variable_scope('gen', reuse=reuse):\n",
    "        hidden1 = tf.layers.dense(inputs=z,units=128)\n",
    "        #leaky Relu\n",
    "        alpha=0.01\n",
    "        hidden1 = tf.maximum(alpha*hidden1, hidden1)\n",
    "        hidden2 = tf.layers.dense(inputs=hidden1, units=128)\n",
    "        \n",
    "        hidden2 = tf.maximum(alpha*hidden2, hidden2)\n",
    "        output = tf.layers.dense(hidden2, units=784, activation=tf.nn.tanh)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discriminator(X, reuse=None):\n",
    "    with tf.variable_scope('dis',reuse=reuse):\n",
    "        hidden1 = tf.layers.dense(inputs=X, units=128)\n",
    "        # Leaky Relu\n",
    "        alpha = 0.01\n",
    "        hidden1 = tf.maximum(alpha*hidden1, hidden1)\n",
    "        \n",
    "        hidden2 = tf.layers.dense(inputs=hidden1, units=128)\n",
    "        hidden2 = tf.maximum(alpha*hidden2, hidden2)\n",
    "        \n",
    "        logits = tf.layers.dense(hidden2, units=1)\n",
    "        output = tf.sigmoid(logits)\n",
    "        \n",
    "        return output, logits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Placeholders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_images = tf.placeholder(tf.float32, shape=[None, 784])\n",
    "z = tf.placeholder(tf.float32, shape=[None, 100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = generator(z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "D_output_real , D_logits_real = discriminator(real_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "D_output_fake , D_logits_fake = discriminator(G, reuse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_func(logits_in, labels_in):\n",
    "    return tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=logits_in, labels=labels_in))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "D_real_loss = loss_func(D_logits_real, tf.ones_like(D_logits_real)*(0.9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "D_fake_loss = loss_func(D_logits_fake, tf.zeros_like(D_logits_real))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "D_loss = D_real_loss + D_fake_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "G_loss = loss_func(D_logits_fake, tf.ones_like(D_logits_fake))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['dis/dense/kernel:0', 'dis/dense/bias:0', 'dis/dense_1/kernel:0', 'dis/dense_1/bias:0', 'dis/dense_2/kernel:0', 'dis/dense_2/bias:0']\n",
      "['gen/dense/kernel:0', 'gen/dense/bias:0', 'gen/dense_1/kernel:0', 'gen/dense_1/bias:0', 'gen/dense_2/kernel:0', 'gen/dense_2/bias:0']\n"
     ]
    }
   ],
   "source": [
    "tvars = tf.trainable_variables()\n",
    "\n",
    "d_vars = [var for var in tvars if 'dis' in var.name]\n",
    "g_vars = [var for var in tvars if 'gen' in var.name]\n",
    "\n",
    "print ([v.name for v in d_vars])\n",
    "print ([v.name for v in g_vars])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "D_trainer = tf.train.AdamOptimizer(learning_rate).minimize(D_loss, var_list=d_vars)\n",
    "G_trainer = tf.train.AdamOptimizer(learning_rate).minimize(G_loss, var_list=g_vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'dis/dense/kernel:0' shape=(784, 128) dtype=float32_ref>,\n",
       " <tf.Variable 'dis/dense/bias:0' shape=(128,) dtype=float32_ref>,\n",
       " <tf.Variable 'dis/dense_1/kernel:0' shape=(128, 128) dtype=float32_ref>,\n",
       " <tf.Variable 'dis/dense_1/bias:0' shape=(128,) dtype=float32_ref>,\n",
       " <tf.Variable 'dis/dense_2/kernel:0' shape=(128, 1) dtype=float32_ref>,\n",
       " <tf.Variable 'dis/dense_2/bias:0' shape=(1,) dtype=float32_ref>]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_vars"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 100\n",
    "epochs = 1000\n",
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver(var_list=g_vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save a sample per epoch\n",
    "samples = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    \n",
    "    sess.run(init)\n",
    "    \n",
    "    # Recall an epoch is an entire run through the training data\n",
    "    for e in range(epochs):\n",
    "        # indicates classic division\n",
    "        num_batches = mnist.train.num_examples // batch_size\n",
    "        \n",
    "        for i in range(num_batches):\n",
    "            \n",
    "            # Grab batch of images\n",
    "            batch = mnist.train.next_batch(batch_size)\n",
    "            \n",
    "            # Get images, reshape and rescale to pass to D\n",
    "            batch_images = batch[0].reshape((batch_size, 784))\n",
    "            batch_images = batch_images*2 -1\n",
    "            \n",
    "            # Z (random latent noise data for Generator)\n",
    "            # -1 to 1 because of tanh activation\n",
    "            batch_z = np.random.uniform(-1, 1, size=(batch_size, 100))\n",
    "            \n",
    "            # Run optimizers, no need to save outputs, we won't use them\n",
    "            _ = sess.run(D_trainer, feed_dict={real_images: batch_images, z: batch_z})\n",
    "            _ = sess.run(G_trainer, feed_dict={z: batch_z})\n",
    "            \n",
    "        print(\"Currently on Epoch {} of {} total...\".format(e+1, epochs))\n",
    "        \n",
    "        # Sample from generator as we're training for viewing afterwards\n",
    "        sample_z = np.random.uniform(-1, 1, size=(1, 100))\n",
    "        gen_sample = sess.run(generator(z , reuse=True), feed_dict={z: sample_z})\n",
    "        \n",
    "        samples.append(gen_sample)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
